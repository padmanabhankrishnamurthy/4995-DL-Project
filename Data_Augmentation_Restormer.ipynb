{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJsIo6sMaFjG"
   },
   "source": [
    "# Nate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9DnqQePNgz1"
   },
   "outputs": [],
   "source": [
    "# ! pip3 install -r /content/drive/MyDrive/Final\\ Project/VRGNet/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xK1WpQMmaK-c"
   },
   "source": [
    "# Restormer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xDq4mQs3APtQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../generated_data_restormer/\")\n",
    "os.makedirs(\"../generated_data_restormer/crop_patch/\")\n",
    "os.makedirs(\"../generated_data_restormer/fake_rain_layer\")\n",
    "os.makedirs(\"../generated_data_restormer/rain_fake\")\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Mto2WqEaSEQ",
    "outputId": "8c82804e-395c-42cd-9a28-aeb0f4669ab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████████████████████████████▏                                                                                                                              | 3599/13711 [00:35<01:38, 102.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3673/1463271819.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;31m# plt.imshow(O)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from vrgnet import EDNet  # EDNet: RNet+G\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.io as sio\n",
    "from numpy.random import RandomState\n",
    "from skimage import  exposure\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# data_path = \"/content/drive/MyDrive/Final Project/VRGNet/input_data/rain\"\n",
    "# gt_path = \"/content/drive/MyDrive/Final Project/VRGNet/input_data/no_rain\"\n",
    "data_path = \"../../train/Rain13K/input\"\n",
    "gt_path = \"../../train/Rain13K/target\"\n",
    "nc = 3 \n",
    "patch_size = 64\n",
    "nz = 128\n",
    "stage = 6\n",
    "nef = 32\n",
    "use_gpu = True\n",
    "gpu_id = \"0\"\n",
    "\n",
    "#netEDPath = \"./spamodels/ED_state_800.pt\"\n",
    "# netEDPath = '/content/drive/MyDrive/Final Project/VRGNet/for_syn/syn100hmodels/ED_state_700.pt'\n",
    "# use rain14000 model\n",
    "netEDPath = \"syn1400models/ED_state_700.pt\"\n",
    "save_patch = \"../generated_data_restormer/crop_patch/\"\n",
    "save_fake_rain_layer = \"../generated_data_restormer/fake_rain_layer\"\n",
    "save_rainfake = \"../generated_data_restormer/rain_fake\"\n",
    "num_crops = 5\n",
    "num_crops = 1\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n",
    "\n",
    "def is_image(img_name):\n",
    "    if img_name.endswith(\".jpg\") or img_name.endswith(\".bmp\") or img_name.endswith(\".png\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def crop(img, crop_sample):\n",
    "    h, w, c = img.shape\n",
    "    p_h, p_w = patch_size, patch_size\n",
    "    rand_state = RandomState(66*crop_sample)\n",
    "    r = rand_state.randint(0, h - p_h)\n",
    "    c = rand_state.randint(0, w - p_w)\n",
    "    O = img[r: r + p_h, c : c + p_w]\n",
    "    return O,r,c\n",
    "\n",
    "print('Loading model ...\\n')\n",
    "netED = EDNet(nc, nz, nef).cuda()\n",
    "netED.load_state_dict(torch.load(netEDPath))\n",
    "netED.eval()\n",
    "z_list=[]\n",
    "B_list=[]\n",
    "G_list=[]\n",
    "image_list = os.listdir(data_path)\n",
    "\n",
    "# print(len(image_list))\n",
    "# 13711\n",
    "\n",
    "for img_name in tqdm(image_list):\n",
    "    if is_image(img_name):\n",
    "        img_path = os.path.join(data_path, img_name)\n",
    "        # gt_img_path = os.path.join(gt_path, \"norain\" + img_name[4::])\n",
    "        gt_img_path = os.path.join(gt_path, img_name)\n",
    "\n",
    "        # print(img_path, gt_img_path)\n",
    "\n",
    "        # plt.imshow(cv2.imread(img_path))\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(cv2.imread(gt_img_path))\n",
    "        # plt.show()\n",
    "\n",
    "        # sys.exit()\n",
    "\n",
    "        for crop_sample in range(0,num_crops,1):\n",
    "\n",
    "            # input image\n",
    "            O = cv2.imread(img_path)\n",
    "            # plt.imshow(O)\n",
    "            # plt.show()\n",
    "            b, g, r = cv2.split(O)\n",
    "            input_img = cv2.merge([r, g, b])\n",
    "            # plt.imshow(input_img)\n",
    "            # plt.show()\n",
    "            # input_img_test = cv2.imread(img_path)\n",
    "            # plt.imshow(input_img_test)\n",
    "            # plt.show()\n",
    "            # input_img_test_rgb = cv2.cvtColor(input_img_test, cv2.COLOR_BGR2RGB)\n",
    "            # plt.imshow(input_img_test_rgb)\n",
    "            # plt.show()\n",
    "\n",
    "            # crop input to 64x64 and save\n",
    "            # O, row, col = crop(input_img, crop_sample)\n",
    "            # resize to 64x64\n",
    "            O = cv2.resize(O, (64, 64))\n",
    "            O = O.astype(np.float32) / 255\n",
    "            O_patch = O\n",
    "            b, g, r = cv2.split(O)\n",
    "            O = cv2.merge([r, g, b])\n",
    "            # plt.imshow(O)\n",
    "            # cv2_imshow(O)\n",
    "            # plt.show()\n",
    "            #cv2.imwrite(os.path.join(save_patch, f\"{crop_sample}\" + img_name), np.uint8(255 * O))\n",
    "            # plt.imsave(\"/content/pixelated.jpg\", O)\n",
    "\n",
    "            \n",
    "\n",
    "            # crop gt image to 64*64\n",
    "            B = cv2.imread(gt_img_path)\n",
    "            #resize to 64x64\n",
    "            # print(gt_img_path)\n",
    "            b, g, r = cv2.split(B)\n",
    "            gt_img = cv2.merge([r, g, b])\n",
    "            # B = gt_img[row: row + patch_size, col: col + patch_size]\n",
    "            B = cv2.resize(B, (64, 64))\n",
    "            B = B.astype(np.float32) / 255\n",
    "            B_patch = B\n",
    "\n",
    "            # plt.imshow(B)\n",
    "            # cv2_imshow(B)\n",
    "            # plt.show()\n",
    "\n",
    "            # B_patch = B\n",
    "            # save the original rain patch\n",
    "            Rain_patch = O_patch-B_patch\n",
    "            b, g, r = cv2.split(Rain_patch)\n",
    "            Rain_patch = cv2.merge([r, g, b])\n",
    "            # cv2.imwrite((save_patch + '/'+  f\"{crop_sample}\" + img_name),np.uint8(255*B_patch))\n",
    "\n",
    "            # plt.imshow(Rain_patch)\n",
    "            # plt.show()\n",
    "\n",
    "            # execute latent space interpolation for patch image\n",
    "            O = np.expand_dims(O_patch.transpose(2, 0, 1), 0)\n",
    "            O = Variable(torch.Tensor(O)).cuda()\n",
    "            B = np.expand_dims(B_patch.transpose(2, 0, 1), 0)\n",
    "            B = torch.Tensor(B).cuda()\n",
    "            B_list.append(B)\n",
    "            with torch.no_grad():  #\n",
    "                if use_gpu:\n",
    "                    torch.cuda.synchronize()\n",
    "                _, _, _,z = netED(O) # z: 1*nz\n",
    "                z_list.append(z)\n",
    "\n",
    "            # break\n",
    "    # break\n",
    "\n",
    "print(len(B_list))\n",
    "print(len(z_list))\n",
    "\n",
    "# sys.exit()\n",
    "\n",
    "for idx, img_name in enumerate(tqdm(image_list)):\n",
    "\n",
    "    # idx = idx*5\n",
    "    idx = idx*num_crops\n",
    "    \n",
    "    for crop_sample in range(0,num_crops,1):\n",
    "        # print(idx+crop_sample)\n",
    "\n",
    "        z_mix = z_list[idx+crop_sample]\n",
    "        rain_fake = netED.sample(z_mix)\n",
    "        rain_fake_max = torch.max(rain_fake,1)[0]\n",
    "        rain_fake = rain_fake_max.unsqueeze(dim=1).expand_as(rain_fake) #gray rain layer\n",
    "\n",
    "\n",
    "        fake = B_list[idx+crop_sample] + rain_fake\n",
    "        fake = torch.clamp(fake, 0, 1)\n",
    "        fake = np.uint8(255 * fake.data.cpu().numpy().squeeze()).transpose(1, 2, 0)\n",
    "\n",
    "        # plt.imshow(cv2.cvtColor(fake, cv2.COLOR_BGR2RGB))\n",
    "        # plt.show()\n",
    "\n",
    "        # adjust brightness\n",
    "        rain_fake = torch.clamp(rain_fake, 0, 1)\n",
    "        rain_fake = np.uint8(255*rain_fake.data.cpu().numpy().squeeze()).transpose(1, 2, 0)\n",
    "        rain_fake = exposure.adjust_gamma(rain_fake,0.7)\n",
    "\n",
    "        # plt.imshow(rain_fake)\n",
    "        # plt.show()\n",
    "\n",
    "        # bg label\n",
    "        label = torch.clamp(B_list[idx+crop_sample], 0, 1)\n",
    "        label = np.uint8(255*label.data.cpu().numpy().squeeze()).transpose(1, 2, 0)\n",
    "\n",
    "        # plt.imshow(label)\n",
    "        # plt.show()\n",
    "\n",
    "        img_name = img_name[:img_name.rfind('.')] + '.png'\n",
    "\n",
    "        #rain-1.png\n",
    "        # print(save_rainfake + '/'+ f\"rain-\" + img_name)\n",
    "        plt.imsave(save_rainfake + '/'+ f\"rain-\" + img_name, fake[:,:,::-1]/255) # rainy image\n",
    "\n",
    "        #norain-1.png\n",
    "        # print(save_patch + '/'+ f\"norain-\" + img_name)\n",
    "        plt.imsave(save_patch + '/'+ f\"norain-\" + img_name, label[:,:,::-1]/255)\n",
    "\n",
    "\n",
    "        #rainstreak-1.png\n",
    "        # print(save_fake_rain_layer + '/'+ f\"rainstreak-\" + img_name)\n",
    "        plt.imsave(save_fake_rain_layer + '/' + f\"rainstreak-\" + img_name, rain_fake[:,:,::-1]/255) \n",
    "\n",
    "        # print(save_rainfake + '/'+ f\"fake_\" + f\"{crop_sample}\" + img_name)\n",
    "\n",
    "        # plt.imsave(save_rainfake + '/'+ f\"fake_\" + f\"{crop_sample}\" + img_name, fake/255) # rainy image\n",
    "        # plt.imsave(save_fake_rain_layer + '/' + f\"fake_\" + f\"{crop_sample}\" + img_name, rain_fake/255)\n",
    "\n",
    "        # break\n",
    "\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKPH3BSE6Moi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Data_Augmentation_Restormer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
