{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline-restormer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Rain100H Test data"
      ],
      "metadata": {
        "id": "SM82urD3avKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWVlTq45afFF",
        "outputId": "c9578ade-53ee-47be-ce6f-0604c8c51ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 01:07:48--  https://hkustconnect-my.sharepoint.com/:u:/g/personal/nnanda_connect_ust_hk/EY3EbMx3FL9FoLlstrD6xrkBHur6fU6You3ppuqg_SOUDQ?download=1\n",
            "Resolving hkustconnect-my.sharepoint.com (hkustconnect-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to hkustconnect-my.sharepoint.com (hkustconnect-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/nnanda_connect_ust_hk/Documents/DL/test.zip?ga=1 [following]\n",
            "--2022-03-31 01:07:49--  https://hkustconnect-my.sharepoint.com/personal/nnanda_connect_ust_hk/Documents/DL/test.zip?ga=1\n",
            "Reusing existing connection to hkustconnect-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1360310555 (1.3G) [application/x-zip-compressed]\n",
            "Saving to: ‘test.zip’\n",
            "\n",
            "test.zip            100%[===================>]   1.27G  65.9MB/s    in 24s     \n",
            "\n",
            "2022-03-31 01:08:14 (53.4 MB/s) - ‘test.zip’ saved [1360310555/1360310555]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://hkustconnect-my.sharepoint.com/:u:/g/personal/nnanda_connect_ust_hk/EY3EbMx3FL9FoLlstrD6xrkBHur6fU6You3ppuqg_SOUDQ?download=1\" -O \"test.zip\"\n",
        "!unzip -q test.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "9aiYkg59bAln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from runpy import run_path\n",
        "from skimage import img_as_ubyte\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import argparse"
      ],
      "metadata": {
        "id": "YOChk02CaroZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Restormer Model"
      ],
      "metadata": {
        "id": "5JjNEu55bNlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "\n",
        "if os.path.isdir('Restormer'):\n",
        "  !rm -r Restormer\n",
        "\n",
        "# Clone Restormer\n",
        "!git clone https://github.com/swz30/Restormer.git\n",
        "%cd Restormer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6jT7CWWbAbt",
        "outputId": "713b1c66-3162-4135-ff55-c7ac03f9ce85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Cloning into 'Restormer'...\n",
            "remote: Enumerating objects: 275, done.\u001b[K\n",
            "remote: Counting objects: 100% (275/275), done.\u001b[K\n",
            "remote: Compressing objects: 100% (211/211), done.\u001b[K\n",
            "remote: Total 275 (delta 100), reused 165 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (275/275), 1.54 MiB | 6.56 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "/content/Restormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deraining Pretrained model\n",
        "!wget https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth -P Deraining/pretrained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qThpD4WRbZh2",
        "outputId": "b5848cd8-056d-4f47-f9ba-e75ecb50761c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 01:08:36--  https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/20ec86ee-8bea-45fe-b188-a1fd18b739fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220331%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220331T010836Z&X-Amz-Expires=300&X-Amz-Signature=cd30442b73fe1c403666b36a112e177a3a9cedc3caa85bd3063beb0a018ac261&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=418793252&response-content-disposition=attachment%3B%20filename%3Dderaining.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-03-31 01:08:36--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/20ec86ee-8bea-45fe-b188-a1fd18b739fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220331%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220331T010836Z&X-Amz-Expires=300&X-Amz-Signature=cd30442b73fe1c403666b36a112e177a3a9cedc3caa85bd3063beb0a018ac261&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=418793252&response-content-disposition=attachment%3B%20filename%3Dderaining.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104700429 (100M) [application/octet-stream]\n",
            "Saving to: ‘Deraining/pretrained_models/deraining.pth’\n",
            "\n",
            "deraining.pth       100%[===================>]  99.85M  76.4MB/s    in 1.3s    \n",
            "\n",
            "2022-03-31 01:08:38 (76.4 MB/s) - ‘Deraining/pretrained_models/deraining.pth’ saved [104700429/104700429]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pretrained Restormer"
      ],
      "metadata": {
        "id": "4VQBOZXibvXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights_and_parameters(parameters):\n",
        "    weights = os.path.join('Deraining', 'pretrained_models', 'deraining.pth')\n",
        "\n",
        "    return weights, parameters\n",
        "\n",
        "\n",
        "# Get model weights and parameters\n",
        "parameters = {'inp_channels':3, 'out_channels':3, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'WithBias', 'dual_pixel_task':False}\n",
        "weights, parameters = get_weights_and_parameters(parameters)\n",
        "\n",
        "load_arch = run_path(os.path.join('basicsr', 'models', 'archs', 'restormer_arch.py'))\n",
        "model = load_arch['Restormer'](**parameters)\n",
        "model.cuda()\n",
        "\n",
        "checkpoint = torch.load(weights)\n",
        "model.load_state_dict(checkpoint['params'])\n",
        "print(model.eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uskMinQNa65E",
        "outputId": "45f45630-fa71-4a56-ff82-74559c90d283"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restormer(\n",
            "  (patch_embed): OverlapPatchEmbed(\n",
            "    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  )\n",
            "  (encoder_level1): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
            "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
            "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
            "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
            "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down1_2): Downsample(\n",
            "    (body): Sequential(\n",
            "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): PixelUnshuffle(downscale_factor=2)\n",
            "    )\n",
            "  )\n",
            "  (encoder_level2): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down2_3): Downsample(\n",
            "    (body): Sequential(\n",
            "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): PixelUnshuffle(downscale_factor=2)\n",
            "    )\n",
            "  )\n",
            "  (encoder_level3): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down3_4): Downsample(\n",
            "    (body): Sequential(\n",
            "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): PixelUnshuffle(downscale_factor=2)\n",
            "    )\n",
            "  )\n",
            "  (latent): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
            "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up4_3): Upsample(\n",
            "    (body): Sequential(\n",
            "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): PixelShuffle(upscale_factor=2)\n",
            "    )\n",
            "  )\n",
            "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (decoder_level3): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
            "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up3_2): Upsample(\n",
            "    (body): Sequential(\n",
            "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): PixelShuffle(upscale_factor=2)\n",
            "    )\n",
            "  )\n",
            "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (decoder_level2): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up2_1): Upsample(\n",
            "    (body): Sequential(\n",
            "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): PixelShuffle(upscale_factor=2)\n",
            "    )\n",
            "  )\n",
            "  (decoder_level1): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (refinement): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (norm1): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (attn): Attention(\n",
            "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (norm2): LayerNorm(\n",
            "        (body): WithBias_LayerNorm()\n",
            "      )\n",
            "      (ffn): FeedForward(\n",
            "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
            "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions on Rain100H test data"
      ],
      "metadata": {
        "id": "wQVg9RUib2vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newpath = '/content/test/Rain100H/restormer'\n",
        "if not os.path.exists(newpath):\n",
        "    os.makedirs(newpath)"
      ],
      "metadata": {
        "id": "Mmkr9-b0byRm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = '/content/test/Rain100H/input'\n",
        "out_dir = '/content/test/Rain100H/restormer'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "extensions = ['jpg', 'JPG', 'png', 'PNG', 'jpeg', 'JPEG', 'bmp', 'BMP']\n",
        "files = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "\n",
        "img_multiple_of = 8\n",
        "\n",
        "print(f\"\\n ==> Running Deraining with weights {weights}\\n \")\n",
        "with torch.no_grad():\n",
        "  for filepath in tqdm(files):\n",
        "      # print(file_)\n",
        "      torch.cuda.ipc_collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
        "      input_ = torch.from_numpy(img).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "\n",
        "      # Pad the input if not_multiple_of 8\n",
        "      h,w = input_.shape[2], input_.shape[3]\n",
        "      H,W = ((h+img_multiple_of)//img_multiple_of)*img_multiple_of, ((w+img_multiple_of)//img_multiple_of)*img_multiple_of\n",
        "      padh = H-h if h%img_multiple_of!=0 else 0\n",
        "      padw = W-w if w%img_multiple_of!=0 else 0\n",
        "      input_ = F.pad(input_, (0,padw,0,padh), 'reflect')\n",
        "\n",
        "      restored = model(input_)\n",
        "      restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "      # Unpad the output\n",
        "      restored = restored[:,:,:h,:w]\n",
        "\n",
        "      restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "      restored = img_as_ubyte(restored[0])\n",
        "\n",
        "      filename = os.path.split(filepath)[-1]\n",
        "      cv2.imwrite(os.path.join(out_dir, filename),cv2.cvtColor(restored, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6PyY9KPb7el",
        "outputId": "dab93a2d-730b-4024-b24f-45f1871ac7a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ==> Running Deraining with weights Deraining/pretrained_models/deraining.pth\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:58<00:00,  1.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Baseline Metric - PSNR"
      ],
      "metadata": {
        "id": "6h9m4ztrcKT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb2ycbcr(im_rgb):\n",
        "    im_rgb = im_rgb.astype(np.float32)\n",
        "    im_ycrcb = cv2.cvtColor(im_rgb, cv2.COLOR_RGB2YCR_CB)\n",
        "    im_ycbcr = im_ycrcb[:,:,(0,2,1)].astype(np.float32)\n",
        "    im_ycbcr[:,:,0] = (im_ycbcr[:,:,0]*(235-16)+16)/255.0 #to [16/255, 235/255]\n",
        "    im_ycbcr[:,:,1:] = (im_ycbcr[:,:,1:]*(240-16)+16)/255.0 #to [16/255, 240/255]\n",
        "    return im_ycbcr"
      ],
      "metadata": {
        "id": "u4BByhYzcJ39"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dir = '/content/test/Rain100H/restormer'\n",
        "targets_dir = '/content/test/Rain100H/target'\n",
        "\n",
        "preds_files = natsorted(glob(os.path.join(preds_dir, '*')))\n",
        "targets_files = natsorted(glob(os.path.join(targets_dir, '*')))\n",
        "\n",
        "preds_targets = list(zip(preds_files, targets_files))\n",
        "print(preds_targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4uxjdHDcEhF",
        "outputId": "f4dd508a-c8d7-444d-d383-a37534b812a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('/content/test/Rain100H/restormer/1.png', '/content/test/Rain100H/target/1.png')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate PSNR\n",
        "total_psnr = 0\n",
        "\n",
        "for tup in preds_targets:\n",
        "    pred = cv2.cvtColor(cv2.imread(tup[0]), cv2.COLOR_BGR2RGB)\n",
        "    label = cv2.cvtColor(cv2.imread(tup[1]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    pred_ycbcr = rgb2ycbcr(pred)\n",
        "    label_ycbcr = rgb2ycbcr(label)\n",
        "\n",
        "    rmse = np.sqrt(np.mean((pred_ycbcr[:, :, 0] - label_ycbcr[:, :, 0])**2))\n",
        "\n",
        "    psnr = 20 * np.log10(255 / rmse)\n",
        "\n",
        "    total_psnr += psnr\n",
        "\n",
        "print(total_psnr / len(preds_targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQnQETmlcWox",
        "outputId": "98714287-6120-451f-cd9c-f1bb56739c34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31.476724949953812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M681rYqLc8Nv"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}